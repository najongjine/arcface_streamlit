# -*- coding: utf-8 -*-
"""Insightface_train_test.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pVuvk2HPuCQh6qNvh3RxU9STpqu7drZN
"""

!pip install -U insightface
!pip install onnxruntime
!pip install faiss-cpu

from google.colab import drive
drive.mount('/content/drive')

import insightface
import faiss
import cv2
import numpy as np
from pathlib import Path
import pandas as pd
import pickle
import albumentations as A
from albumentations.pytorch import ToTensorV2
import os

save_path = "/content/drive/MyDrive/embedding/person"
data_folder="/content/drive/MyDrive/dataset/person"
os.makedirs(save_path, exist_ok=True)  # í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±

# ğŸš€ ëª¨ë¸ ì¤€ë¹„ (GPU ì‚¬ìš© ì‹œ ctx_id=0)
model = insightface.app.FaceAnalysis(name='buffalo_l', providers=['CPUExecutionProvider'])
model.prepare(ctx_id=0)

augment = A.Compose([
    A.HorizontalFlip(p=0.5),
    A.RandomBrightnessContrast(p=0.3),
    A.Rotate(limit=15, p=0.3),
])

# ğŸš€ ì„ë² ë”© ì¶”ì¶œ í•¨ìˆ˜
def get_face_embedding(image_path: str, n_augment: int = 5):
    img = cv2.imread(str(image_path))
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    embeddings = []

    # âœ… ì›ë³¸ ì´ë¯¸ì§€ ë¨¼ì € ì„ë² ë”©
    faces = model.get(img)
    if faces:
        embeddings.append(faces[0].embedding)
    else:
        print(f"âŒ ì–¼êµ´ ì¸ì‹ ì‹¤íŒ¨ (ì›ë³¸): {image_path}")

    # âœ… ì´í›„ ì¦ê°• ì´ë¯¸ì§€ë“¤ ì„ë² ë”©
    for i in range(n_augment):
        augmented = augment(image=img)
        img_aug = augmented['image']
        faces = model.get(img_aug)
        if faces:
            embeddings.append(faces[0].embedding)
        else:
            print(f"âŒ ì–¼êµ´ ì¸ì‹ ì‹¤íŒ¨ (ì¦ê°• {i+1}): {image_path}")

    if embeddings:
        return np.mean(embeddings, axis=0)
    else:
        print(f"âŒ ëª¨ë“  ì‹œë„ ì‹¤íŒ¨: {image_path}")
        return None



# ğŸš€ í´ë” ì²˜ë¦¬ í•¨ìˆ˜
def process_folder(base_path):
    data = []
    base_path = Path(base_path)
    for person_dir in base_path.iterdir():
        if not person_dir.is_dir():
            continue
        label = person_dir.name
        print(f"â–¶ í´ë”: {label}")
        count = 0
        for image_path in list(person_dir.glob("*")):
            if image_path.suffix.lower() not in [".jpg", ".jpeg", ".png"]:
                continue
            emb = get_face_embedding(image_path)
            if emb is not None:
                count += 1
                data.append({
                    "label": label,
                    "image_path": str(image_path),
                    "embedding": emb
                })
        print(f"âœ… ì–¼êµ´ ì¸ì‹ ì„±ê³µ ìˆ˜: {count}")
    return pd.DataFrame(data)

# ğŸš€ ë°ì´í„°ì…‹ ìƒì„±
train_df = process_folder(data_folder)

# ğŸš€ embedding ìŠ¤íƒ
embeddings = np.stack(train_df['embedding'].values).astype('float32')
embeddings /= np.linalg.norm(embeddings, axis=1, keepdims=True)   # â­ï¸ ì •ê·œí™”

# ğŸš€ FAISS ì¸ë±ìŠ¤ ìƒì„± (ì½”ì‚¬ì¸ ìœ ì‚¬ë„ â‰ˆ ë‚´ì )
index = faiss.IndexFlatIP(embeddings.shape[1])
index.add(embeddings)

# ğŸš€ ë¼ë²¨ ë¦¬ìŠ¤íŠ¸ ì €ì¥
labels = train_df['label'].tolist()

# ğŸš€ ì¸ë±ìŠ¤ ì €ì¥
faiss.write_index(index, f"{save_path}/faiss_index.index")

# ğŸš€ ë¼ë²¨ë„ ê°™ì´ ì €ì¥
with open(f"{save_path}/faiss_labels.pkl", "wb") as f:
    pickle.dump(labels, f)

print("âœ… FAISS ì¸ë±ìŠ¤ & ë¼ë²¨ ì €ì¥ ì™„ë£Œ")